#!/usr/bin/env python3
"""
Vietnam News Aggregation Sample

This sample demonstrates how to extract news articles from Vietnamese news sources
like VnExpress, Tuoi Tre, Thanh Nien, and Dan Tri.
"""

import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from pydantic import BaseModel
from typing import List, Optional, Dict

from nova_act import NovaAct


class VietnamNewsArticle(BaseModel):
    title: str
    summary: str
    author: Optional[str]
    publication_date: Optional[str]
    source: str
    category: Optional[str]
    url: str
    sentiment: Optional[str]  # t√≠ch c·ª±c, ti√™u c·ª±c, trung t√≠nh
    key_topics: List[str]
    view_count: Optional[str] = None
    comment_count: Optional[str] = None
    extracted_at: str


class VietnamNewsAggregator:
    def __init__(self):
        self.articles = []
    
    def extract_articles_from_source(self, source_config: dict, topic: str, max_articles: int = 5) -> List[VietnamNewsArticle]:
        """Extract articles from a Vietnamese news source"""
        articles = []
        
        try:
            with NovaAct(starting_page=source_config['url']) as nova:
                # Search for the topic if search is available
                if source_config.get('has_search', True):
                    nova.act(f"t√¨m ki·∫øm '{topic}'")
                
                # Extract multiple articles
                for i in range(max_articles):
                    try:
                        # Navigate to article
                        if i == 0:
                            nova.act("nh·∫•p v√†o b√†i vi·∫øt ƒë·∫ßu ti√™n li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ")
                        else:
                            nova.act("quay l·∫°i trang tr∆∞·ªõc")
                            nova.act(f"nh·∫•p v√†o b√†i vi·∫øt th·ª© {i+1} li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ")
                        
                        # Extract article details
                        article_schema = VietnamNewsArticle.model_json_schema()
                        result = nova.act(
                            f"""Tr√≠ch xu·∫•t th√¥ng tin b√†i vi·∫øt m·ªôt c√°ch chi ti·∫øt:
                            - Ti√™u ƒë·ªÅ b√†i vi·∫øt
                            - T√≥m t·∫Øt ng·∫Øn g·ªçn (2-3 c√¢u)
                            - T√™n t√°c gi·∫£ (n·∫øu c√≥)
                            - Ng√†y xu·∫•t b·∫£n (n·∫øu c√≥)
                            - Chuy√™n m·ª•c/danh m·ª•c (n·∫øu c√≥)
                            - Ph√¢n t√≠ch c·∫£m x√∫c (t√≠ch c·ª±c/ti√™u c·ª±c/trung t√≠nh)
                            - X√°c ƒë·ªãnh 3-5 t·ª´ kh√≥a ch√≠nh ho·∫∑c ch·ªß ƒë·ªÅ
                            - S·ªë l∆∞·ª£t xem (n·∫øu c√≥)
                            - S·ªë b√¨nh lu·∫≠n (n·∫øu c√≥)
                            
                            S·ª≠ d·ª•ng source: '{source_config['name']}' v√† URL hi·ªán t·∫°i
                            """,
                            schema=article_schema
                        )
                        
                        if result.matches_schema:
                            article = VietnamNewsArticle.model_validate(result.parsed_response)
                            article.extracted_at = datetime.now().isoformat()
                            articles.append(article)
                            print(f"‚úì ƒê√£ tr√≠ch xu·∫•t: {article.title[:50]}...")
                        
                    except Exception as e:
                        print(f"L·ªói tr√≠ch xu·∫•t b√†i vi·∫øt {i+1} t·ª´ {source_config['name']}: {e}")
                        continue
                        
        except Exception as e:
            print(f"L·ªói truy c·∫≠p {source_config['name']}: {e}")
        
        return articles
    
    def aggregate_vietnam_news(self, topic: str, sources: List[dict], max_workers: int = 2) -> List[VietnamNewsArticle]:
        """Aggregate news from multiple Vietnamese sources"""
        all_articles = []
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_source = {
                executor.submit(self.extract_articles_from_source, source, topic): source 
                for source in sources
            }
            
            for future in as_completed(future_to_source.keys()):
                source_config = future_to_source[future]
                try:
                    articles = future.result()
                    all_articles.extend(articles)
                    print(f"‚úì {source_config['name']}: {len(articles)} b√†i vi·∫øt")
                except Exception as e:
                    print(f"‚úó L·ªói v·ªõi {source_config['name']}: {e}")
        
        self.articles.extend(all_articles)
        return all_articles
    
    def analyze_vietnam_sentiment(self, articles: List[VietnamNewsArticle]) -> Dict:
        """Analyze sentiment trends in Vietnamese news"""
        sentiment_counts = {"t√≠ch c·ª±c": 0, "ti√™u c·ª±c": 0, "trung t√≠nh": 0}
        sentiment_by_source = {}
        
        for article in articles:
            if article.sentiment:
                sentiment_counts[article.sentiment] = sentiment_counts.get(article.sentiment, 0) + 1
                
                if article.source not in sentiment_by_source:
                    sentiment_by_source[article.source] = {"t√≠ch c·ª±c": 0, "ti√™u c·ª±c": 0, "trung t√≠nh": 0}
                sentiment_by_source[article.source][article.sentiment] += 1
        
        total_articles = len(articles)
        sentiment_percentages = {
            sentiment: (count / total_articles * 100) if total_articles > 0 else 0
            for sentiment, count in sentiment_counts.items()
        }
        
        return {
            "overall_sentiment": sentiment_counts,
            "sentiment_percentages": sentiment_percentages,
            "sentiment_by_source": sentiment_by_source
        }
    
    def extract_vietnam_trending_topics(self, articles: List[VietnamNewsArticle]) -> List[Dict]:
        """Extract and rank trending topics in Vietnamese news"""
        topic_frequency = {}
        
        for article in articles:
            for topic in article.key_topics:
                topic_lower = topic.lower()
                topic_frequency[topic_lower] = topic_frequency.get(topic_lower, 0) + 1
        
        # Sort by frequency
        trending_topics = sorted(topic_frequency.items(), key=lambda x: x[1], reverse=True)
        
        return [
            {"topic": topic.title(), "frequency": freq, "percentage": (freq / len(articles) * 100)}
            for topic, freq in trending_topics[:20]
        ]
    
    def analyze_vietnam_categories(self, articles: List[VietnamNewsArticle]) -> Dict:
        """Analyze news categories in Vietnamese media"""
        category_stats = {}
        
        for article in articles:
            if article.category:
                category = article.category.lower()
                category_stats[category] = category_stats.get(category, 0) + 1
        
        # Sort by frequency
        top_categories = sorted(category_stats.items(), key=lambda x: x[1], reverse=True)
        
        return {
            "total_categories": len(category_stats),
            "category_distribution": category_stats,
            "top_categories": [
                {"category": cat.title(), "count": count, "percentage": (count / len(articles) * 100)}
                for cat, count in top_categories
            ]
        }
    
    def generate_vietnam_news_report(self, topic: str, articles: List[VietnamNewsArticle]) -> Dict:
        """Generate comprehensive Vietnamese news analysis report"""
        if not articles:
            return {"error": "Kh√¥ng c√≥ b√†i vi·∫øt ƒë·ªÉ ph√¢n t√≠ch"}
        
        # Basic statistics
        sources = list(set(article.source for article in articles))
        
        # Sentiment analysis
        sentiment_analysis = self.analyze_vietnam_sentiment(articles)
        
        # Trending topics
        trending_topics = self.extract_vietnam_trending_topics(articles)
        
        # Category analysis
        category_analysis = self.analyze_vietnam_categories(articles)
        
        # Source analysis
        articles_by_source = {}
        for article in articles:
            if article.source not in articles_by_source:
                articles_by_source[article.source] = []
            articles_by_source[article.source].append(article)
        
        # Engagement analysis (views and comments)
        engagement_stats = self._analyze_engagement(articles)
        
        return {
            "topic": topic,
            "analysis_date": datetime.now().isoformat(),
            "summary": {
                "total_articles": len(articles),
                "sources_covered": len(sources),
                "categories_found": len(set(a.category for a in articles if a.category))
            },
            "sources": sources,
            "sentiment_analysis": sentiment_analysis,
            "trending_topics": trending_topics[:10],
            "category_analysis": category_analysis,
            "engagement_statistics": engagement_stats,
            "articles_by_source": {
                source: len(articles) for source, articles in articles_by_source.items()
            },
            "sample_headlines": [article.title for article in articles[:10]],
            "recommendations": self._generate_news_recommendations(articles),
            "detailed_articles": [article.dict() for article in articles]
        }
    
    def _analyze_engagement(self, articles: List[VietnamNewsArticle]) -> Dict:
        """Analyze engagement metrics of Vietnamese news articles"""
        articles_with_views = [a for a in articles if a.view_count]
        articles_with_comments = [a for a in articles if a.comment_count]
        
        return {
            "articles_with_view_count": len(articles_with_views),
            "articles_with_comment_count": len(articles_with_comments),
            "engagement_rate": (len(articles_with_comments) / len(articles) * 100) if articles else 0
        }
    
    def _generate_news_recommendations(self, articles: List[VietnamNewsArticle]) -> List[str]:
        """Generate recommendations for Vietnamese news consumption"""
        recommendations = []
        
        if not articles:
            return recommendations
        
        # Most active source
        source_counts = {}
        for article in articles:
            source_counts[article.source] = source_counts.get(article.source, 0) + 1
        
        most_active_source = max(source_counts.items(), key=lambda x: x[1])
        recommendations.append(f"Ngu·ªìn tin t√≠ch c·ª±c nh·∫•t: {most_active_source[0]} v·ªõi {most_active_source[1]} b√†i vi·∫øt")
        
        # Sentiment recommendation
        sentiment_counts = {"t√≠ch c·ª±c": 0, "ti√™u c·ª±c": 0, "trung t√≠nh": 0}
        for article in articles:
            if article.sentiment:
                sentiment_counts[article.sentiment] += 1
        
        dominant_sentiment = max(sentiment_counts.items(), key=lambda x: x[1])
        recommendations.append(f"Xu h∆∞·ªõng c·∫£m x√∫c ch·ªß ƒë·∫°o: {dominant_sentiment[0]} ({dominant_sentiment[1]} b√†i vi·∫øt)")
        
        # Category recommendation
        categories = {}
        for article in articles:
            if article.category:
                categories[article.category] = categories.get(article.category, 0) + 1
        
        if categories:
            top_category = max(categories.items(), key=lambda x: x[1])
            recommendations.append(f"Chuy√™n m·ª•c ƒë∆∞·ª£c quan t√¢m nh·∫•t: {top_category[0]} ({top_category[1]} b√†i vi·∫øt)")
        
        return recommendations
    
    def save_report(self, report: Dict, filename: str = None):
        """Save Vietnamese news report to JSON file"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            topic_safe = report.get('topic', 'news').replace(' ', '_').lower()
            filename = f"vietnam_news_report_{topic_safe}_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"B√°o c√°o tin t·ª©c ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o {filename}")


def main():
    # Vietnamese news sources to aggregate from
    vietnam_news_sources = [
        {
            'name': 'VnExpress',
            'url': 'https://vnexpress.net',
            'has_search': True
        },
        {
            'name': 'Tuoi Tre',
            'url': 'https://tuoitre.vn',
            'has_search': True
        },
        {
            'name': 'Thanh Nien',
            'url': 'https://thanhnien.vn',
            'has_search': True
        },
        {
            'name': 'Dan Tri',
            'url': 'https://dantri.com.vn',
            'has_search': True
        }
    ]
    
    # Topic to research
    topic = "c√¥ng ngh·ªá AI"
    
    aggregator = VietnamNewsAggregator()
    
    print(f"üì∞ T·ªïng h·ª£p tin t·ª©c v·ªÅ '{topic}' t·ª´ {len(vietnam_news_sources)} ngu·ªìn...")
    
    # Aggregate Vietnamese news articles
    articles = aggregator.aggregate_vietnam_news(topic, vietnam_news_sources)
    
    if articles:
        print(f"\nüìä ƒê√£ tr√≠ch xu·∫•t th√†nh c√¥ng {len(articles)} b√†i vi·∫øt")
        
        # Generate comprehensive report
        report = aggregator.generate_vietnam_news_report(topic, articles)
        
        # Display key insights
        print(f"\nüìà T√≥m t·∫Øt ph·ªß s√≥ng:")
        print(f"  ‚Ä¢ T·ªïng s·ªë b√†i vi·∫øt: {report['summary']['total_articles']}")
        print(f"  ‚Ä¢ Ngu·ªìn tin: {report['summary']['sources_covered']}")
        print(f"  ‚Ä¢ Chuy√™n m·ª•c: {report['summary']['categories_found']}")
        
        print(f"\nüòä Ph√¢n t√≠ch c·∫£m x√∫c:")
        sentiment = report['sentiment_analysis']['sentiment_percentages']
        print(f"  ‚Ä¢ T√≠ch c·ª±c: {sentiment['t√≠ch c·ª±c']:.1f}%")
        print(f"  ‚Ä¢ Trung t√≠nh: {sentiment['trung t√≠nh']:.1f}%")
        print(f"  ‚Ä¢ Ti√™u c·ª±c: {sentiment['ti√™u c·ª±c']:.1f}%")
        
        print(f"\nüî• Ch·ªß ƒë·ªÅ n·ªïi b·∫≠t:")
        for topic_data in report['trending_topics'][:5]:
            print(f"  ‚Ä¢ {topic_data['topic']}: {topic_data['frequency']} l·∫ßn xu·∫•t hi·ªán ({topic_data['percentage']:.1f}%)")
        
        print(f"\nüì∞ Ti√™u ƒë·ªÅ m·∫´u:")
        for headline in report['sample_headlines'][:3]:
            print(f"  ‚Ä¢ {headline}")
        
        if 'recommendations' in report:
            print(f"\nüí° Khuy·∫øn ngh·ªã:")
            for rec in report['recommendations']:
                print(f"  ‚Ä¢ {rec}")
        
        # Save detailed report
        aggregator.save_report(report)
        
    else:
        print("‚ùå Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt ƒë·ªÉ ph√¢n t√≠ch")


if __name__ == "__main__":
    main()
